orbs:
  python: circleci/python@2.0.3
version: 2.1
jobs:
  run-tests:
    environment:
      RELEASE_NAME: example-release
    machine:
      image: ubuntu-2004:202107-02
    resource_class: large
    steps:
    - checkout
    - run:
        name: Install Kind
        command: |
          curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.11.1/kind-linux-amd64
          chmod +x ./kind
          sudo mv ./kind /usr/local/bin/
    - run:
       name: create kind cluster
       command: |
         kind create cluster --image kindest/node:v1.21.1

    - run:
       name: Install jq
       command: |
         sudo apt-get update
         sudo apt-get install -y jq

    - run:
        name: Install kubectl
        command: |
          curl -Lo kubectl https://storage.googleapis.com/kubernetes-release/release/v1.12.0/bin/linux/amd64/kubectl
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

    - run:
        name: install helm
        command: |
          curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
          chmod +x get_helm.sh
          ./get_helm.sh
          helm repo add apache-airflow https://airflow.apache.org
          helm repo update

    - run:
       name: Install airflow
       command: |
          helm install $RELEASE_NAME apache-airflow/airflow -f ./values.yaml

    - run:
        name: verify airflow installed
        command: |
            kubectl get pods
            POD_NAME=($(kubectl get pods | grep -E 'worker' | awk '{print $1}'))
            echo "Pod Name: $POD_NAME"
            kubectl exec -it  $POD_NAME -- airflow version
            sleep 180s 
            kubectl exec -it  $POD_NAME -- airflow dags list
            kubectl exec -it  $POD_NAME -- airflow dags unpause init_dag
            output=$(kubectl exec -it  $POD_NAME -- airflow dags trigger init_dag -o json | awk 'NR==2' | sed 's/\x1B\[[0-9;]*[mGK]//g')  
            echo "output is : $output"
            execution_date=$(echo $output | jq -r '.[0].logical_date')
            echo "execution_date: $execution_date"
            # Add a loop to check the DAG state until it becomes 'success' or 'failed'
            kubectl exec -it $POD_NAME -- airflow dags state init_dag $execution_date
            while true; do
              state=$(kubectl exec -it $POD_NAME -- airflow dags state init_dag $execution_date |  awk '{print $1}' | sed 's/\x1B\[[0-9;]*[mGK]//g')
              echo "state is $state"
              if [ "$state" == "success" ]; then
                echo "DAG state is $state."
                exit 0
              elif [ "$state" == "failed" ]; then
                 echo "DAG state is $state."
                exit 1
              else
                echo "DAG state is $state waiting for it to become 'success' or 'failed..."
                sleep 300  # You can adjust the sleep interval as needed
              fi
            done
             
              
             
             
          
             

workflows:
  turbulence-ci:
    jobs:
    - run-tests:
        context:
        - turbulence
        name: setup_airflow_env

